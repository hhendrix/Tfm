{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43630889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e5fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('E:\\Python\\Modelos\\Test.Lenet.2.h5')\n",
    "#model = tf.keras.models.load_model('E:\\Python\\Modelos\\Test.Alexnet.h5')\n",
    "#model = tf.keras.models.load_model('E:\\Python\\Modelos\\Test1.2.h5')\n",
    "#model = tf.keras.models.load_model('E:\\Python\\Modelos\\Test2.2.h5')\n",
    "model = tf.keras.models.load_model('E:\\Python\\Modelos\\Test2.5.h5')\n",
    "#model = tf.keras.models.load_model('E:\\Python\\Modelos\\Test3.1.h5')\n",
    "#model = tf.keras.models.load_model('E:\\Python\\Modelos\\Test3.2.h5')\n",
    "#model = tf.keras.models.load_model('E:\\Python\\Modelos\\Test6.1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd524f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LABELS = ['Abuse','Arrest','Arson','Assault',\n",
    "                'Burglary','Explosion','Fighting',\"Normal\",\n",
    "                'RoadAccidents','Robbery','Shooting',\n",
    "                'Shoplifting','Stealing','Vandalism']\n",
    "CLASS_LABELS2 = ['Anomalia','Normal']\n",
    "\n",
    "#PATH_IMAGE = \"/Users/harry.lopez/Documents/Dataset/Test Video/Asalto.mp4\"\n",
    "#PATH_IMAGE = \"/Users/harry.lopez/Documents/Dataset/Test Video/ExplosionesVideo.mp4\"\n",
    "PATH_IMAGE = \"E:\\Python\\Videos\\RoadAccidents022_x264.mp4\"\n",
    "PREDICTION_IMAGE = []\n",
    "PREDICTION_TEXT = []\n",
    "PREDICTION_VIDEO = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6582844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def display_images(img_list,title_list, cmap='gray', cols = 5, fig_size = (20, 20) ):\n",
    "    \"\"\"\n",
    "    Display images in img_list\n",
    "    \"\"\"\n",
    "    i = 1  # for subplot\n",
    "\n",
    "    num_images = len(img_list)\n",
    "    #num_rows = int(num_images / cols)\n",
    "    num_rows = 8\n",
    "\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.subplots_adjust(top = 1.0)\n",
    "\n",
    "    for image in img_list:\n",
    "        if i < 40:\n",
    "            image_file_name = title_list[i - 1]\n",
    "            plt.subplot(num_rows, cols, i)        \n",
    "            plt.title(image_file_name,fontsize=15,color=\"green\", pad='2.0')\n",
    "            plt.imshow(image, cmap=cmap)        \n",
    "        i += 1     \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "329a3e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateModel(pathImage, modelFunc, nameModel, classes):\n",
    "    #cap = cv2.VideoCapture('/Users/harry.lopez/Documents/Dataset/Dataset/Vandalism/Vandalism033_x264.mp4')\n",
    "    cap = cv2.VideoCapture(pathImage)\n",
    "    ret, frame = cap.read()\n",
    "    count = 0\n",
    "    predictionIds = []\n",
    "    countFrames = 0;\n",
    "    frameArray = []\n",
    "    predictionFrame = []\n",
    "\n",
    "    # Mientras haya fotogramas\n",
    "    while ret:\n",
    "        # Redimensiona el fotograma a las dimensiones de entrada del modelo\n",
    "        frame = cv2.resize(frame, (64, 64))\n",
    "\n",
    "        # Convierte el fotograma a un tensor de una sola dimensión\n",
    "        input_data = np.expand_dims(frame, axis=0)\n",
    "\n",
    "        # Hace una predicción sobre el fotograma\n",
    "        prediction = modelFunc.predict(input_data, verbose = 0)\n",
    "\n",
    "        #print('Prediction:', prediction)\n",
    "        index = indices = np.where(prediction[0] == prediction[0].max())\n",
    "        predictionIds.append(index)\n",
    "        #print('index', CLASS_LABELS[index[0][0]])\n",
    "\n",
    "        if countFrames == 50:\n",
    "            predictionFrame.append(classes[index[0][0]] + '=Frame:' + str(count))\n",
    "            frameArray.append(frame)\n",
    "            countFrames = 0\n",
    "        else:\n",
    "            countFrames += 1\n",
    "        ret, frame = cap.read()\n",
    "        count += 1\n",
    "\n",
    "\n",
    "    # Libera el video\n",
    "    print(\"Cantidad de Fotogramas:\", count)\n",
    "    print(\"Modelo de Prueba:\", nameModel)\n",
    "    cap.release()\n",
    "    display_images(frameArray,predictionFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e927e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateModelVideo(pathImage, modelFunc, nameModel, \n",
    "                       classes, width, height):\n",
    "    cap = cv2.VideoCapture(pathImage)\n",
    "    \n",
    "    count = 0\n",
    "    predictionIds = []\n",
    "    countFrames = 0;\n",
    "    frameArray = []\n",
    "    predictionFrame = []\n",
    "\n",
    "    # Mientras haya fotogramas\n",
    "    while (cap.isOpened()):\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        # Redimensiona el fotograma a las dimensiones de entrada del modelo\n",
    "        frame2 = cv2.resize(frame, (width, height))\n",
    "        \n",
    "        frame = cv2.resize(frame, (64, 64))\n",
    "\n",
    "        # Convierte el fotograma a un tensor de una sola dimensión\n",
    "        input_data = np.expand_dims(frame, axis=0)\n",
    "        \n",
    "        # Hace una predicción sobre el fotograma\n",
    "        prediction = modelFunc.predict(input_data, verbose = 0)\n",
    "        \n",
    "        index = indices = np.where(prediction[0] == prediction[0].max())\n",
    "        predictionIds.append(index)\n",
    "\n",
    "        #Obtener el index de os tres mayores puntajes\n",
    "        scores = np.argsort(prediction[0])[::-1][:3]\n",
    "        \n",
    "        #obtener los  valores de los 3 mayores puntajes\n",
    "        predictionValues = prediction[0][scores]\n",
    "        \n",
    "        #Obtener en texto los  valores de las tre mayores predicciones\n",
    "        predictionString = classes[scores[0]] + ' Score:' \n",
    "        + \"{:.2f}\".format(predictionValues[0] * 100)\n",
    "        predictionString1 = classes[scores[1]] + ' Score:' \n",
    "        + \"{:.2f}\".format(predictionValues[1] * 100)\n",
    "        predictionString2 = classes[scores[2]] + ' Score:' \n",
    "        + \"{:.2f}\".format(predictionValues[2] * 100)\n",
    "        \n",
    "        #POner en el frame los valores obtenidos\n",
    "        cv2.putText(frame2, predictionString, (45,45), \n",
    "                    cv2.FONT_HERSHEY_TRIPLEX, 2.0, (0,0,255), 1)\n",
    "        cv2.putText(frame2, predictionString1, (45,100), \n",
    "                    cv2.FONT_HERSHEY_TRIPLEX, 2.0, (0,0,255), 1)\n",
    "        cv2.putText(frame2, predictionString2, (45,155), \n",
    "                    cv2.FONT_HERSHEY_TRIPLEX, 2.0, (0,0,255), 1)\n",
    "\n",
    "        #Almacenar los index de las predicciones\n",
    "        PREDICTION_VIDEO.append(scores)\n",
    "        \n",
    "        #Contar los frames evalulados\n",
    "        count += 1\n",
    "        \n",
    "        #Mostrar el frame analizado\n",
    "        cv2.imshow('Capture', frame2)\n",
    "        \n",
    "        #Opciòn para salir en el proceso \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    # Libera el video\n",
    "    print(\"Cantidad de Fotogramas:\", count)\n",
    "    print(\"Modelo de Prueba:\", nameModel)\n",
    "    cap.release()\n",
    "    display_images(frameArray,predictionFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validateModelVideo(PATH_IMAGE, model, \n",
    "                   'Model Test 3-2-3', \n",
    "                   CLASS_LABELS, 1024, 780)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
